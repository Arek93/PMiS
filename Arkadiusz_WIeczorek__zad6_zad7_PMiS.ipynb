{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Arkadiusz_WIeczorek_ zad6_zad7_PMiS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arek93/PMiS/blob/main/Arkadiusz_WIeczorek__zad6_zad7_PMiS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0.6 Modele rozwoju epidemii\n",
        "Ćwiczenie polega na dobieraniu parametrów modelu do danych doświadczalnych\n",
        "dotyczących COVID-19. Dane można znaleźć m. in tu: https://ourworldindata.org/coronavirus Każda osoba analizuje inny kraj (proszę to uzgodnić w grupie)\n",
        "\n",
        "* na ocenę 3 - model Malthusa ( pasuje tylko do początku epidemii)\n",
        "* na ocenę 4 model logistyczny (obejmuje wysycanie ale nie ozdrowienia)\n",
        "* na ocenę 5 - porównanie modeli logistycznych Verhulst - Gompertz, lub\n",
        "eksperymentalne dobieranie parametrów do modelu SIR\n",
        "\n",
        "\n",
        "Fitowanie krzywej należy wykonać przy pomocy dowolnej biblioteki"
      ],
      "metadata": {
        "id": "xBwEajxoTkEM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wybrany kraj: **Bahama** - [Link do danych](https://ourworldindata.org/explorers/coronavirus-data-explorer?zoomToSelection=true&time=2020-07-13..2021-02-07&facet=none&pickerSort=asc&pickerMetric=location&Metric=Confirmed+cases&Interval=7-day+rolling+average&Relative+to+Population=true&Color+by+test+positivity=false&country=~BHS), przedział czasowy **od 13.07.2020 do 07.02.2020** \n",
        "\n",
        "Do wykonania zadania wykorzystam model logistyczny **Verhulsta**.\n",
        "\n"
      ],
      "metadata": {
        "id": "4rUf7gJfUZeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import math\n",
        "import scipy.optimize as optim\n",
        "\n",
        "\n",
        "# import pliku\n",
        "# plik został przeze mnie wyczyszczony ze zbędnych danych\n",
        "data = pd.read_csv('https://github.com/Arek93/PMiS/blob/main/bahama_covid.csv', sep=';')\n",
        "data = data['total_cases']\n",
        "data = data.reset_index(drop=False)\n",
        "data.columns = ['Timestep', 'Total Cases']\n",
        "\n",
        "# funkcje logistyczne\n",
        "def my_logistic(t, a, b, c):\n",
        "  return c / (1 + a * np.exp(-b*t))\n",
        "def my_logistic2(t):\n",
        "  return c / (1 + a * np.exp(-b*t))\n",
        "\n",
        "# losowa inicjalizacja parametrów a, b i c\n",
        "p0 = np.random.exponential(size=3)\n",
        "\n",
        "#ustawienie górnych i dolnych ograniczeć dla a, b i c\n",
        "bounds = (0, [100000., 3., 1000000000.])\n",
        "\n",
        "# dopasowanie krzywej\n",
        "x = np.array(data['Timestep']) + 1\n",
        "y = np.array(data['Total Cases'])\n",
        "(a,b,c),cov = optim.curve_fit(my_logistic, x, y, bounds=bounds, p0=p0)\n",
        "\n",
        "# wykreślenie funkcji w porównaniu z rzeczywistymi danymi\n",
        "plt.scatter(x, y)\n",
        "plt.plot(x, my_logistic2(x), color=\"red\")\n",
        "plt.title('Logistic Model vs Real Observations of UKR COVID')\n",
        "plt.legend(['Logistic Model', 'Real data'])\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Infections')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "SKKxlGT-2Hkj",
        "outputId": "9c08936d-5ae4-499b-cffd-a20b1d4d9e4b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-f03f626b5f74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# import pliku\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# plik został przeze mnie wyczyszczony ze zbędnych danych\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://github.com/Arek93/PMiS/blob/main/bahama_covid.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_cases'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 160, saw 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Podsumowanie:\n",
        "Na podstawie powyższego wykresu widzimy, że udało się znaleźć funkcję logistyczną, bardzo zbliżoną do właściwych danych COVID z Ukrainy. "
      ],
      "metadata": {
        "id": "-zz1uvKPCOUs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#0.7 Automaty komórkowe\n",
        "Zaprojektuj dwuwymiarowy automat komórkowy realizujący dowolny algorytm oparty na regułach sąsiedztwa.\n",
        "\n",
        "### Płatek Śniegu:"
      ],
      "metadata": {
        "id": "HBe9epLsTOWT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "size = 10\n",
        "def neigh():\n",
        "  nearest=[[0 for _ in range(size)] for _ in range(size)]\n",
        "  for y in range(size):\n",
        "    for x in range(size):\n",
        "      nearest[y][x] = count(y,x)\n",
        "  return nearest\n",
        "\n",
        "def count(y, x):\n",
        "  dy=[0,0,1,-1]\n",
        "  dx=[-1,1,0,0]\n",
        "  count = 0\n",
        "  for k in range(len(dx)):\n",
        "    kx=(x+dx[k]) % size\n",
        "    ky=(y+dy[k]) % size\n",
        "    count=count+tab[ky][kx]\n",
        "  return count\n",
        " \n",
        "def inicialize(y,x):\n",
        "  tab=[[0 for _ in range(y)] for _ in range(x)]\n",
        "  tab[4][4]=1\n",
        "  tab[4][5]=1\n",
        "  return tab\n",
        " \n",
        "def print_tab(tab):\n",
        "  for y in range(size):\n",
        "    for x in range(size):\n",
        "      print(tab[x][y], end=' ')\n",
        "    print(' ')\n",
        "\n",
        " \n",
        "tab=inicialize(size,size)\n",
        "print_tab(tab)\n",
        "print('====================')\n",
        "for x in range(size):\n",
        "  nearest = neigh()\n",
        "  res=tab\n",
        "  for y in range(size):\n",
        "      for x in range(size):\n",
        "        if tab[y][x] == 0:\n",
        "          if nearest[y][x]==1:\n",
        "            res[y][x]=1\n",
        "  tab=res\n",
        "  print_tab(tab)\n",
        "  print('====================')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkYsnEAsScuU",
        "outputId": "1bda4d9f-4dce-4206-fbd6-2386b63289a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0 0 0 0 0 0 0 0 0  \n",
            "0 0 0 0 0 0 0 0 0 0  \n",
            "0 0 0 0 0 0 0 0 0 0  \n",
            "0 0 0 0 0 0 0 0 0 0  \n",
            "0 0 0 0 1 0 0 0 0 0  \n",
            "0 0 0 0 1 0 0 0 0 0  \n",
            "0 0 0 0 0 0 0 0 0 0  \n",
            "0 0 0 0 0 0 0 0 0 0  \n",
            "0 0 0 0 0 0 0 0 0 0  \n",
            "0 0 0 0 0 0 0 0 0 0  \n",
            "====================\n",
            "0 0 0 0 0 0 0 0 0 0  \n",
            "0 0 0 0 0 0 0 0 0 0  \n",
            "0 0 0 0 0 0 0 0 0 0  \n",
            "0 0 0 0 1 0 0 0 0 0  \n",
            "0 0 0 1 1 1 0 0 0 0  \n",
            "0 0 0 1 1 1 0 0 0 0  \n",
            "0 0 0 0 1 0 0 0 0 0  \n",
            "0 0 0 0 0 0 0 0 0 0  \n",
            "0 0 0 0 0 0 0 0 0 0  \n",
            "0 0 0 0 0 0 0 0 0 0  \n",
            "====================\n",
            "0 0 0 0 0 0 0 0 0 0  \n",
            "0 0 0 0 0 0 0 0 0 0  \n",
            "0 0 0 0 1 0 0 0 0 0  \n",
            "0 0 0 0 1 0 0 0 0 0  \n",
            "0 0 1 1 1 1 1 0 0 0  \n",
            "0 0 1 1 1 1 1 0 0 0  \n",
            "0 0 0 0 1 0 0 0 0 0  \n",
            "0 0 0 0 1 0 0 0 0 0  \n",
            "0 0 0 0 0 0 0 0 0 0  \n",
            "0 0 0 0 0 0 0 0 0 0  \n",
            "====================\n",
            "0 0 0 0 0 0 0 0 0 0  \n",
            "0 0 0 0 1 0 0 0 0 0  \n",
            "0 0 0 1 1 1 0 0 0 0  \n",
            "0 0 1 0 1 0 1 0 0 0  \n",
            "0 1 1 1 1 1 1 1 0 0  \n",
            "0 1 1 1 1 1 1 1 0 0  \n",
            "0 0 1 0 1 0 1 0 0 0  \n",
            "0 0 0 1 1 1 0 0 0 0  \n",
            "0 0 0 0 1 0 0 0 0 0  \n",
            "0 0 0 0 0 0 0 0 0 0  \n",
            "====================\n",
            "0 0 0 0 1 0 0 0 0 0  \n",
            "0 0 0 0 1 0 0 0 0 0  \n",
            "0 0 0 1 1 1 0 0 0 0  \n",
            "0 0 1 0 1 0 1 0 0 0  \n",
            "1 1 1 1 1 1 1 1 1 0  \n",
            "1 1 1 1 1 1 1 1 1 0  \n",
            "0 0 1 0 1 0 1 0 0 0  \n",
            "0 0 0 1 1 1 0 0 0 0  \n",
            "0 0 0 0 1 0 0 0 0 0  \n",
            "0 0 0 0 1 0 0 0 0 0  \n",
            "====================\n",
            "0 0 0 1 1 1 0 0 0 0  \n",
            "0 0 0 0 1 0 0 0 0 0  \n",
            "0 0 0 1 1 1 0 0 0 0  \n",
            "1 0 1 0 1 0 1 0 1 0  \n",
            "1 1 1 1 1 1 1 1 1 0  \n",
            "1 1 1 1 1 1 1 1 1 0  \n",
            "1 0 1 0 1 0 1 0 1 0  \n",
            "0 0 0 1 1 1 0 0 0 0  \n",
            "0 0 0 0 1 0 0 0 0 0  \n",
            "0 0 0 1 1 1 0 0 0 0  \n",
            "====================\n",
            "0 0 1 1 1 1 1 0 0 0  \n",
            "0 0 0 0 1 0 0 0 0 0  \n",
            "1 0 0 1 1 1 0 0 1 0  \n",
            "1 0 1 0 1 0 1 0 1 0  \n",
            "1 1 1 1 1 1 1 1 1 0  \n",
            "1 1 1 1 1 1 1 1 1 0  \n",
            "1 0 1 0 1 0 1 0 1 0  \n",
            "1 0 0 1 1 1 0 0 1 0  \n",
            "0 0 0 0 1 0 0 0 0 0  \n",
            "0 0 1 1 1 1 1 0 0 0  \n",
            "====================\n",
            "0 1 1 1 1 1 1 1 0 0  \n",
            "1 0 1 0 1 0 1 0 1 0  \n",
            "1 1 0 1 1 1 0 1 1 0  \n",
            "1 0 1 0 1 0 1 0 1 0  \n",
            "1 1 1 1 1 1 1 1 1 0  \n",
            "1 1 1 1 1 1 1 1 1 0  \n",
            "1 0 1 0 1 0 1 0 1 0  \n",
            "1 1 0 1 1 1 0 1 1 0  \n",
            "1 0 1 0 1 0 1 0 1 0  \n",
            "0 1 1 1 1 1 1 1 0 0  \n",
            "====================\n",
            "0 1 1 1 1 1 1 1 0 0  \n",
            "1 0 1 0 1 0 1 0 1 0  \n",
            "1 1 0 1 1 1 0 1 1 0  \n",
            "1 0 1 0 1 0 1 0 1 0  \n",
            "1 1 1 1 1 1 1 1 1 0  \n",
            "1 1 1 1 1 1 1 1 1 0  \n",
            "1 0 1 0 1 0 1 0 1 0  \n",
            "1 1 0 1 1 1 0 1 1 0  \n",
            "1 0 1 0 1 0 1 0 1 0  \n",
            "0 1 1 1 1 1 1 1 0 0  \n",
            "====================\n",
            "0 1 1 1 1 1 1 1 0 0  \n",
            "1 0 1 0 1 0 1 0 1 0  \n",
            "1 1 0 1 1 1 0 1 1 0  \n",
            "1 0 1 0 1 0 1 0 1 0  \n",
            "1 1 1 1 1 1 1 1 1 0  \n",
            "1 1 1 1 1 1 1 1 1 0  \n",
            "1 0 1 0 1 0 1 0 1 0  \n",
            "1 1 0 1 1 1 0 1 1 0  \n",
            "1 0 1 0 1 0 1 0 1 0  \n",
            "0 1 1 1 1 1 1 1 0 0  \n",
            "====================\n",
            "0 1 1 1 1 1 1 1 0 0  \n",
            "1 0 1 0 1 0 1 0 1 0  \n",
            "1 1 0 1 1 1 0 1 1 0  \n",
            "1 0 1 0 1 0 1 0 1 0  \n",
            "1 1 1 1 1 1 1 1 1 0  \n",
            "1 1 1 1 1 1 1 1 1 0  \n",
            "1 0 1 0 1 0 1 0 1 0  \n",
            "1 1 0 1 1 1 0 1 1 0  \n",
            "1 0 1 0 1 0 1 0 1 0  \n",
            "0 1 1 1 1 1 1 1 0 0  \n",
            "====================\n"
          ]
        }
      ]
    }
  ]
}